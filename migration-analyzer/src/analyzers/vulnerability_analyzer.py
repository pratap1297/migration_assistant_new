"""
Vulnerability analyzer that either integrates with real tools or provides honest assessments
This fixes the misleading "0 vulnerabilities" issue
"""
import os
import json
import re
import subprocess
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from pathlib import Path
from datetime import datetime, timedelta
from .llm_security_synthesizer import LLMSecuritySynthesizer
from ..config import get_api_key

@dataclass
class VulnerabilityFinding:
    """A vulnerability finding"""
    id: str
    severity: str  # CRITICAL, HIGH, MEDIUM, LOW
    title: str
    description: str
    file_path: str
    line_number: Optional[int]
    cve_id: Optional[str]
    package: Optional[str]
    version: Optional[str]
    fixed_version: Optional[str]
    
@dataclass
class VulnerabilityAssessment:
    """Assessment of vulnerabilities"""
    scan_performed: bool
    scan_tool: str
    scan_date: datetime
    findings: List[VulnerabilityFinding]
    outdated_dependencies: List[Dict[str, Any]]
    base_image_risks: List[Dict[str, Any]]
    configuration_issues: List[Dict[str, Any]]
    assessment_notes: List[str]
    
class VulnerabilityAnalyzer:
    """Vulnerability analyzer that provides honest assessments"""
    
    def __init__(self, gemini_api_key: Optional[str] = None):
        # Initialize LLM security synthesizer
        self.llm_synthesizer = LLMSecuritySynthesizer()
        
        # Known vulnerable patterns
        self.vulnerable_patterns = {
            'hardcoded_secrets': [
                r'password\s*=\s*["\'][^"\']+["\']',
                r'api_key\s*=\s*["\'][^"\']+["\']',
                r'secret\s*=\s*["\'][^"\']+["\']',
                r'token\s*=\s*["\'][^"\']+["\']',
                r'-----BEGIN\s+PRIVATE\s+KEY-----',
                r'-----BEGIN\s+RSA\s+PRIVATE\s+KEY-----'
            ],
            'sql_injection': [
                r'query\s*=\s*["\'].*\+.*["\']',
                r'SELECT\s+.*\+.*FROM',
                r'INSERT\s+.*\+.*VALUES',
                r'UPDATE\s+.*\+.*SET'
            ],
            'unsafe_deserialization': [
                r'pickle\.loads\(',
                r'eval\s*\(\s*["\'].*\+.*["\']',  # More specific: eval with concatenated strings
                r'exec\s*\(\s*["\'].*\+.*["\']',  # More specific: exec with concatenated strings
                r'subprocess\.call\(.*\+',
                r'os\.system\(.*\+'
            ]
        }
        
        # Known vulnerable base images
        self.vulnerable_base_images = {
            'node:10': 'Node.js 10 is EOL and contains numerous vulnerabilities',
            'node:10-slim': 'Node.js 10-slim is EOL and contains numerous vulnerabilities',
            'node:12': 'Node.js 12 is EOL and contains vulnerabilities',
            'python:2': 'Python 2 is EOL and contains vulnerabilities',
            'python:3.6': 'Python 3.6 is EOL and contains vulnerabilities',
            'python:3.7': 'Python 3.7 is EOL and contains vulnerabilities',
            'openjdk:8': 'OpenJDK 8 contains known vulnerabilities',
            'maven:3.5': 'Maven 3.5 with JDK 8 contains vulnerabilities',
            'ubuntu:16.04': 'Ubuntu 16.04 is EOL and contains vulnerabilities',
            'ubuntu:18.04': 'Ubuntu 18.04 is approaching EOL',
            'centos:7': 'CentOS 7 is EOL and contains vulnerabilities',
            'alpine:3.8': 'Alpine 3.8 is EOL and contains vulnerabilities'
        }
    
    def analyze_vulnerabilities(self, repo_path: str, components: Dict[str, Any]) -> VulnerabilityAssessment:
        """Analyze vulnerabilities with honest assessment"""
        print(f"VULN-ANALYZER [VULN-ANALYZER] Starting vulnerability analysis for {repo_path}")
        
        findings = []
        outdated_dependencies = []
        base_image_risks = []
        configuration_issues = []
        assessment_notes = []
        
        # Check if we can run real vulnerability scanners
        real_scan_performed = False
        scan_tool = "manual_analysis"
        
        # Try to run Trivy if available
        if self._is_trivy_available():
            print("VULN-ANALYZER [VULN-ANALYZER] Trivy found, attempting real vulnerability scan...")
            trivy_findings = self._run_trivy_scan(repo_path)
            if trivy_findings:
                findings.extend(trivy_findings)
                real_scan_performed = True
                scan_tool = "trivy"
        
        # Perform manual analysis
        manual_findings = self._perform_manual_analysis(repo_path, components)
        findings.extend(manual_findings)
        
        # Analyze base images
        base_image_risks = self._analyze_base_images(components)
        
        # Convert base image risks to findings for consistent reporting
        for risk in base_image_risks:
            base_image_finding = VulnerabilityFinding(
                id=f"BASE_IMAGE_{risk['component'].upper()}",
                severity=risk['risk_level'],
                title=f"Vulnerable Base Image: {risk['base_image']}",
                description=risk['description'],
                file_path=f"{risk['component']}/Dockerfile",
                line_number=1,  # Typically the first line in Dockerfile
                cve_id=None,
                package=risk['base_image'],
                version=risk['base_image'].split(':')[1] if ':' in risk['base_image'] else 'latest',
                fixed_version=risk['recommendation']
            )
            findings.append(base_image_finding)
        
        # Analyze dependencies
        outdated_dependencies = self._analyze_dependencies(repo_path)
        
        # Generate assessment notes
        assessment_notes = self._generate_assessment_notes(
            real_scan_performed, len(findings), base_image_risks, outdated_dependencies
        )
        
        # LLM-ENHANCED: Use intelligent synthesis for consistent reporting
        print(f"VULN-ANALYZER [VULN-ANALYZER] Synthesizing findings with LLM...")
        try:
            security_synthesis = self.llm_synthesizer.synthesize_security_findings(
                findings, base_image_risks, [], len(findings)
            )
            
            # Use synthesized findings for consistent reporting
            findings = [
                VulnerabilityFinding(
                    id=f.id,
                    severity=f.severity,
                    title=f.title,
                    description=f.description,
                    file_path=f.file_path,
                    line_number=f.line_number,
                    cve_id=None,
                    package=None,
                    version=None,
                    fixed_version=f.recommendation
                )
                for f in security_synthesis.findings
            ]
            
            # Add synthesis insights to assessment notes
            assessment_notes.append(f"LLM Synthesis: {security_synthesis.summary}")
            assessment_notes.extend(security_synthesis.confidence_notes)
            
        except Exception as e:
            print(f"⚠️  [VULN-ANALYZER] LLM synthesis failed: {e}")
        
        assessment = VulnerabilityAssessment(
            scan_performed=real_scan_performed,
            scan_tool=scan_tool,
            scan_date=datetime.now(),
            findings=findings,
            outdated_dependencies=outdated_dependencies,
            base_image_risks=base_image_risks,
            configuration_issues=configuration_issues,
            assessment_notes=assessment_notes
        )
        
        print(f"VULN-ANALYZER [VULN-ANALYZER] Analysis complete. Found {len(findings)} potential issues")
        return assessment
    
    def _is_trivy_available(self) -> bool:
        """Check if Trivy is available"""
        try:
            result = subprocess.run(
                ['trivy', '--version'],
                capture_output=True,
                text=True,
                timeout=5
            )
            return result.returncode == 0
        except Exception:
            return False
    
    def _run_trivy_scan(self, repo_path: str) -> List[VulnerabilityFinding]:
        """Run Trivy vulnerability scanner"""
        findings = []
        
        try:
            # Scan filesystem
            result = subprocess.run([
                'trivy', 'fs', '--format', 'json', '--quiet', repo_path
            ], capture_output=True, text=True, timeout=60)
            
            if result.returncode == 0:
                trivy_output = json.loads(result.stdout)
                findings.extend(self._parse_trivy_output(trivy_output))
            
        except subprocess.TimeoutExpired:
            print("⚠️  [VULN-ANALYZER] Trivy scan timed out")
        except Exception as e:
            print(f"⚠️  [VULN-ANALYZER] Error running Trivy: {e}")
        
        return findings
    
    def _parse_trivy_output(self, trivy_output: Dict[str, Any]) -> List[VulnerabilityFinding]:
        """Parse Trivy output into findings"""
        findings = []
        
        if 'Results' in trivy_output:
            for result in trivy_output['Results']:
                if 'Vulnerabilities' in result:
                    for vuln in result['Vulnerabilities']:
                        finding = VulnerabilityFinding(
                            id=vuln.get('VulnerabilityID', 'UNKNOWN'),
                            severity=vuln.get('Severity', 'UNKNOWN'),
                            title=vuln.get('Title', 'Unknown vulnerability'),
                            description=vuln.get('Description', ''),
                            file_path=result.get('Target', 'unknown'),
                            line_number=None,
                            cve_id=vuln.get('VulnerabilityID'),
                            package=vuln.get('PkgName'),
                            version=vuln.get('InstalledVersion'),
                            fixed_version=vuln.get('FixedVersion')
                        )
                        findings.append(finding)
        
        return findings
    
    def _perform_manual_analysis(self, repo_path: str, components: Dict[str, Any]) -> List[VulnerabilityFinding]:
        """Perform manual vulnerability analysis"""
        findings = []
        
        # Scan source files for vulnerable patterns
        for root, dirs, files in os.walk(repo_path):
            # Skip hidden directories and common build directories
            dirs[:] = [d for d in dirs if not d.startswith('.') and 
                      d not in ['node_modules', '__pycache__', 'target', 'build']]
            
            for file in files:
                if file.endswith(('.py', '.js', '.java', '.php', '.rb', '.go')):
                    # Skip minified files and vendor files
                    if (file.endswith('.min.js') or 
                        file.endswith('.min.css') or
                        'vendor' in file.lower() or
                        'node_modules' in root or
                        '.git' in root):
                        continue
                    
                    file_path = os.path.join(root, file)
                    file_findings = self._scan_file_for_vulnerabilities(file_path, repo_path)
                    findings.extend(file_findings)
        
        return findings
    
    def _scan_file_for_vulnerabilities(self, file_path: str, repo_path: str) -> List[VulnerabilityFinding]:
        """Scan a single file for vulnerability patterns"""
        findings = []
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                lines = content.split('\n')
            
            relative_path = os.path.relpath(file_path, repo_path)
            
            # Check for vulnerable patterns
            for vuln_type, patterns in self.vulnerable_patterns.items():
                for pattern in patterns:
                    for line_num, line in enumerate(lines, 1):
                        if re.search(pattern, line, re.IGNORECASE):
                            finding = VulnerabilityFinding(
                                id=f"MANUAL_{vuln_type.upper()}_{line_num}",
                                severity=self._get_severity_for_type(vuln_type),
                                title=f"Potential {vuln_type.replace('_', ' ').title()}",
                                description=f"Pattern detected: {pattern}",
                                file_path=relative_path,
                                line_number=line_num,
                                cve_id=None,
                                package=None,
                                version=None,
                                fixed_version=None
                            )
                            findings.append(finding)
            
        except Exception as e:
            print(f"⚠️  [VULN-ANALYZER] Error scanning {file_path}: {e}")
        
        return findings
    
    def _get_severity_for_type(self, vuln_type: str) -> str:
        """Get severity level for vulnerability type"""
        severity_map = {
            'hardcoded_secrets': 'HIGH',
            'sql_injection': 'HIGH',
            'unsafe_deserialization': 'CRITICAL'
        }
        return severity_map.get(vuln_type, 'MEDIUM')
    
    def _analyze_base_images(self, components: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Analyze base images for known vulnerabilities"""
        base_image_risks = []
        
        for component_name, component in components.items():
            if hasattr(component, 'base_images'):
                for base_image in component.base_images:
                    risk = self._assess_base_image_risk(base_image)
                    if risk:
                        base_image_risks.append({
                            'component': component_name,
                            'base_image': base_image,
                            'risk_level': risk['risk_level'],
                            'description': risk['description'],
                            'recommendation': risk['recommendation']
                        })
        
        return base_image_risks
    
    def _assess_base_image_risk(self, base_image: str) -> Optional[Dict[str, Any]]:
        """Assess risk level of a base image"""
        base_image_lower = base_image.lower()
        
        # Check for known vulnerable images
        for vulnerable_image, description in self.vulnerable_base_images.items():
            if vulnerable_image in base_image_lower:
                return {
                    'risk_level': 'HIGH',
                    'description': description,
                    'recommendation': f"Update to a more recent version of {vulnerable_image.split(':')[0]}"
                }
        
        # Check for very old images
        if any(old_version in base_image_lower for old_version in ['ubuntu:14', 'centos:6', 'alpine:3.6']):
            return {
                'risk_level': 'CRITICAL',
                'description': 'Extremely outdated base image with known vulnerabilities',
                'recommendation': 'Update to a supported version immediately'
            }
        
        return None
    
    def _analyze_dependencies(self, repo_path: str) -> List[Dict[str, Any]]:
        """Analyze dependencies for known issues"""
        outdated_dependencies = []
        
        # Check for common dependency files
        dependency_files = [
            ('package.json', self._analyze_npm_dependencies),
            ('requirements.txt', self._analyze_pip_dependencies),
            ('pom.xml', self._analyze_maven_dependencies),
            ('Gemfile', self._analyze_bundler_dependencies)
        ]
        
        for dep_file, analyzer in dependency_files:
            file_path = os.path.join(repo_path, dep_file)
            if os.path.exists(file_path):
                try:
                    deps = analyzer(file_path)
                    outdated_dependencies.extend(deps)
                except Exception as e:
                    print(f"⚠️  [VULN-ANALYZER] Error analyzing {dep_file}: {e}")
        
        return outdated_dependencies
    
    def _analyze_npm_dependencies(self, file_path: str) -> List[Dict[str, Any]]:
        """Analyze npm dependencies"""
        outdated = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                package_json = json.load(f)
            
            dependencies = package_json.get('dependencies', {})
            
            # Check for known outdated packages
            outdated_packages = {
                'lodash': '4.17.21',
                'moment': '2.29.0',
                'axios': '0.21.1',
                'express': '4.17.1'
            }
            
            for package, version in dependencies.items():
                if package in outdated_packages:
                    outdated.append({
                        'package': package,
                        'current_version': version,
                        'recommended_version': outdated_packages[package],
                        'risk_level': 'MEDIUM',
                        'description': f'{package} may have known vulnerabilities'
                    })
            
        except Exception as e:
            print(f"⚠️  [VULN-ANALYZER] Error parsing package.json: {e}")
        
        return outdated
    
    def _analyze_pip_dependencies(self, file_path: str) -> List[Dict[str, Any]]:
        """Analyze pip dependencies"""
        outdated = []
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Parse requirements.txt
            for line in content.split('\n'):
                line = line.strip()
                if line and not line.startswith('#'):
                    if '==' in line:
                        package, version = line.split('==', 1)
                        # Check for known vulnerable packages
                        if package.lower() in ['flask', 'django', 'requests', 'pyyaml']:
                            outdated.append({
                                'package': package,
                                'current_version': version,
                                'recommended_version': 'latest',
                                'risk_level': 'MEDIUM',
                                'description': f'{package} should be updated to latest version'
                            })
            
        except Exception as e:
            print(f"⚠️  [VULN-ANALYZER] Error parsing requirements.txt: {e}")
        
        return outdated
    
    def _analyze_maven_dependencies(self, file_path: str) -> List[Dict[str, Any]]:
        """Analyze Maven dependencies"""
        # This would require XML parsing for a full implementation
        # For now, return empty list
        return []
    
    def _analyze_bundler_dependencies(self, file_path: str) -> List[Dict[str, Any]]:
        """Analyze Bundler dependencies"""
        # This would require parsing Gemfile syntax
        # For now, return empty list
        return []
    
    def _generate_assessment_notes(self, real_scan_performed: bool, 
                                 findings_count: int, 
                                 base_image_risks: List[Dict[str, Any]], 
                                 outdated_dependencies: List[Dict[str, Any]]) -> List[str]:
        """Generate assessment notes"""
        notes = []
        
        if not real_scan_performed:
            notes.append("WARNING: No automated vulnerability scanner (like Trivy) was available. " +
                        "This analysis is based on manual pattern detection and may miss vulnerabilities.")
        
        if findings_count == 0 and not base_image_risks and not outdated_dependencies:
            notes.append("No obvious vulnerabilities detected in manual analysis, but this does not " +
                        "guarantee the absence of vulnerabilities. A comprehensive security audit with " +
                        "proper tools is recommended.")
        
        if base_image_risks:
            notes.append(f"Found {len(base_image_risks)} base images with known risks. " +
                        "Consider updating to more recent, supported versions.")
        
        if outdated_dependencies:
            notes.append(f"Found {len(outdated_dependencies)} potentially outdated dependencies. " +
                        "Review and update to latest versions.")
        
        notes.append("For production systems, integrate with dedicated vulnerability scanners like " +
                    "Snyk, Veracode, or OWASP Dependency-Check.")
        
        return notes
    
    def get_vulnerability_summary(self, assessment: VulnerabilityAssessment) -> Dict[str, Any]:
        """Get a summary of the vulnerability assessment"""
        critical_count = sum(1 for f in assessment.findings if f.severity == 'CRITICAL')
        high_count = sum(1 for f in assessment.findings if f.severity == 'HIGH')
        medium_count = sum(1 for f in assessment.findings if f.severity == 'MEDIUM')
        low_count = sum(1 for f in assessment.findings if f.severity == 'LOW')
        
        return {
            'scan_performed': assessment.scan_performed,
            'scan_tool': assessment.scan_tool,
            'total_findings': len(assessment.findings),
            'critical_count': critical_count,
            'high_count': high_count,
            'medium_count': medium_count,
            'low_count': low_count,
            'base_image_risks': len(assessment.base_image_risks),
            'outdated_dependencies': len(assessment.outdated_dependencies),
            'assessment_notes': assessment.assessment_notes
        }